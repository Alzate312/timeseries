{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Timeseries SageMaker Template with Gluon\n",
    "\n",
    "This is a template to run the human activity recognition notebook. Refer the `smartphone_human_activity_classification_gluon.ipynb` for non sagemaker version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to run this on SageMaker\n",
    "\n",
    "1. Upload code to the notebook server\n",
    "2. Sync the directory data/har_data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p27/lib/python2.7/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data\n",
    "\n",
    "We use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value `inputs` identifies the location -- we will use this later when we start the training job.\n",
    "\n",
    "** make sure that the code is uploaded to the notebook server first **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='../data/har_data', key_prefix='data/har')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## execute cell below to view the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat har.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training script on SageMaker\n",
    "\n",
    "The ```MXNet``` class allows us to run our training function on SageMaker infrastructure. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. In this case we will run our training job on a single m4.xlarge instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = MXNet(\"har.py\", \n",
    "          role=role, \n",
    "          train_instance_count=1, \n",
    "          train_instance_type=\"ml.m4.xlarge\",\n",
    "          hyperparameters={'batch_size': 32, \n",
    "                         'epochs': 20, \n",
    "                         'learning_rate': 0.01, \n",
    "                         'momentum': 0.9, \n",
    "                         'log_interval': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `MXNet` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-mxnet-py2-cpu-2018-01-28-02-51-24-533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................\n",
      "\u001b[31mexecuting startup script (first run)\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:53,143 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:53,143 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:54,482 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'enable_cloudwatch_metrics': False, 'available_gpus': 0, 'channels': {u'training': {u'TrainingInputMode': u'File', u'RecordWrapperType': u'None', u'S3DistributionType': u'FullyReplicated'}}, '_ps_verbose': 0, 'resource_config': {u'current_host': u'algo-1', u'hosts': [u'algo-1']}, 'user_script_name': u'har.py', 'input_config_dir': '/opt/ml/input/config', 'channel_dirs': {u'training': u'/opt/ml/input/data/training'}, 'code_dir': '/opt/ml/code', 'output_data_dir': '/opt/ml/output/data/', 'output_dir': '/opt/ml/output', 'model_dir': '/opt/ml/model', 'hyperparameters': {u'sagemaker_program': u'har.py', u'learning_rate': 0.01, u'batch_size': 32, u'epochs': 20, u'log_interval': 100, u'sagemaker_region': u'us-west-2', u'sagemaker_enable_cloudwatch_metrics': False, u'sagemaker_job_name': u'sagemaker-mxnet-py2-cpu-2018-01-28-02-51-24-533', u'sagemaker_container_log_level': 20, u'momentum': 0.9, u'sagemaker_submit_directory': u's3://sagemaker-us-west-2-209028685534/sagemaker-mxnet-py2-cpu-2018-01-28-02-51-24-533/source/sourcedir.tar.gz'}, 'hosts': [u'algo-1'], '_ps_port': 8000, 'user_script_archive': u's3://sagemaker-us-west-2-209028685534/sagemaker-mxnet-py2-cpu-2018-01-28-02-51-24-533/source/sourcedir.tar.gz', '_scheduler_host': u'algo-1', 'sagemaker_region': u'us-west-2', 'input_dir': '/opt/ml/input', '_scheduler_ip': '10.32.0.4', 'current_host': u'algo-1', 'container_log_level': 20, 'available_cpus': 4, 'base_dir': '/opt/ml'}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-209028685534/sagemaker-mxnet-py2-cpu-2018-01-28-02-51-24-533/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:54,610 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTP connection (1): 169.254.170.2\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:54,720 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:55,085 INFO - botocore.vendored.requests.packages.urllib3.connectionpool - Starting new HTTPS connection (1): s3.us-west-2.amazonaws.com\u001b[0m\n",
      "\u001b[31m2018-01-28 02:56:55,189 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31m[Epoch 0] [Batch 0/229] Loss: 1.81085, Batch acc: 0.15625\u001b[0m\n",
      "\u001b[31m[Epoch 0] [Batch 100/229] Loss: 1.42154, Batch acc: 0.50000\u001b[0m\n",
      "\u001b[31m[Epoch 0] [Batch 200/229] Loss: 0.99863, Batch acc: 0.43750\u001b[0m\n",
      "\u001b[31mEpoch 0. Loss: 0.93412 Train Acc: ('accuracy', 0.34129366812227074) Test Acc: ('accuracy', 0.28804347826086957)\u001b[0m\n",
      "\u001b[31m[Epoch 1] [Batch 0/229] Loss: 1.59454, Batch acc: 0.25000\u001b[0m\n",
      "\u001b[31m[Epoch 1] [Batch 100/229] Loss: 1.00210, Batch acc: 0.68750\u001b[0m\n",
      "\u001b[31m[Epoch 1] [Batch 200/229] Loss: 0.71509, Batch acc: 0.75000\u001b[0m\n",
      "\u001b[31mEpoch 1. Loss: 0.65546 Train Acc: ('accuracy', 0.6673034934497817) Test Acc: ('accuracy', 0.5822010869565217)\u001b[0m\n",
      "\u001b[31m[Epoch 2] [Batch 0/229] Loss: 0.43700, Batch acc: 0.56250\u001b[0m\n",
      "\u001b[31m[Epoch 2] [Batch 100/229] Loss: 0.56908, Batch acc: 0.65625\u001b[0m\n",
      "\u001b[31m[Epoch 2] [Batch 200/229] Loss: 0.42847, Batch acc: 0.78125\u001b[0m\n",
      "\u001b[31mEpoch 2. Loss: 0.38444 Train Acc: ('accuracy', 0.6974617903930131) Test Acc: ('accuracy', 0.6239809782608695)\u001b[0m\n",
      "\u001b[31m[Epoch 3] [Batch 0/229] Loss: 0.30370, Batch acc: 0.59375\u001b[0m\n",
      "\u001b[31m[Epoch 3] [Batch 100/229] Loss: 0.27614, Batch acc: 0.90625\u001b[0m\n",
      "\u001b[31m[Epoch 3] [Batch 200/229] Loss: 0.50624, Batch acc: 0.71875\u001b[0m\n",
      "\u001b[31mEpoch 3. Loss: 0.48543 Train Acc: ('accuracy', 0.6633460698689956) Test Acc: ('accuracy', 0.6144701086956522)\u001b[0m\n",
      "\u001b[31m[Epoch 4] [Batch 0/229] Loss: 0.38267, Batch acc: 0.62500\u001b[0m\n",
      "\u001b[31m[Epoch 4] [Batch 100/229] Loss: 0.41073, Batch acc: 0.75000\u001b[0m\n",
      "\u001b[31m[Epoch 4] [Batch 200/229] Loss: 0.31628, Batch acc: 0.78125\u001b[0m\n",
      "\u001b[31mEpoch 4. Loss: 0.29615 Train Acc: ('accuracy', 0.6950054585152838) Test Acc: ('accuracy', 0.6423233695652174)\u001b[0m\n",
      "\u001b[31m[Epoch 5] [Batch 0/229] Loss: 0.30729, Batch acc: 0.62500\u001b[0m\n",
      "\u001b[31m[Epoch 5] [Batch 100/229] Loss: 0.25898, Batch acc: 0.68750\u001b[0m\n",
      "\u001b[31m[Epoch 5] [Batch 200/229] Loss: 0.22463, Batch acc: 0.68750\u001b[0m\n",
      "\u001b[31mEpoch 5. Loss: 0.21600 Train Acc: ('accuracy', 0.7378548034934498) Test Acc: ('accuracy', 0.6932744565217391)\u001b[0m\n",
      "\u001b[31m[Epoch 6] [Batch 0/229] Loss: 0.14170, Batch acc: 0.78125\u001b[0m\n",
      "\u001b[31m[Epoch 6] [Batch 100/229] Loss: 0.17564, Batch acc: 0.75000\u001b[0m\n",
      "\u001b[31m[Epoch 6] [Batch 200/229] Loss: 0.19305, Batch acc: 0.68750\u001b[0m\n",
      "\u001b[31mEpoch 6. Loss: 0.18388 Train Acc: ('accuracy', 0.7549126637554585) Test Acc: ('accuracy', 0.7010869565217391)\u001b[0m\n",
      "\u001b[31m[Epoch 7] [Batch 0/229] Loss: 0.10559, Batch acc: 0.68750\u001b[0m\n",
      "\u001b[31m[Epoch 7] [Batch 100/229] Loss: 0.13448, Batch acc: 0.84375\u001b[0m\n",
      "\u001b[31m[Epoch 7] [Batch 200/229] Loss: 0.15890, Batch acc: 0.75000\u001b[0m\n",
      "\u001b[31mEpoch 7. Loss: 0.16503 Train Acc: ('accuracy', 0.7445414847161572) Test Acc: ('accuracy', 0.7075407608695652)\u001b[0m\n",
      "\u001b[31m[Epoch 8] [Batch 0/229] Loss: 0.06994, Batch acc: 0.75000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "m.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
